<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> mini_GPT | Shailesh </title> <meta name="author" content="Shailesh "> <meta name="description" content="A Smaller Version of ChatGPT-3"> <meta name="keywords" content="shailesh, iit, ism, IIT, ISM, Dhanbad, portfolio, resume, Shailesh, Chinchinati, Robotics, Machine Learning, AI, Deep Learning, Reinforcement Learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E3%83%85&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://chinchinati.github.io/projects/7_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Shailesh </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">mini_GPT</h1> <p class="post-description">A Smaller Version of ChatGPT-3</p> </header> <article> <h3 id="project-source-code-github">Project Source Code: <a href="https://github.com/ChinChinati/mini_GPT/" rel="external nofollow noopener" target="_blank">[Github]</a> </h3> <h2 id="overview"><strong>Overview</strong></h2> <p><strong>mini_GPT</strong> is a smaller, custom implementation of a transformer-based language model inspired by ChatGPT-3. Designed to run efficiently on my laptop’s <strong>RTX 4060 GPU</strong>, mini_GPT offers a practical foundation for understanding the architecture and key concepts behind large language models (LLMs). This project focuses on hands-on implementation and training of a scaled-down version of GPT, using the <strong>Shakespeare Dataset</strong> as a text corpus.</p> <h2 id="key-features">Key Features</h2> <ul> <li> <strong>Architecture</strong>: mini_GPT features a transformer-based architecture with: <ul> <li><strong>6 attention heads per layer</strong></li> <li><strong>6 total layers</strong></li> <li><strong>Embedding size of 384</strong></li> </ul> </li> <li> <p><strong>Dataset</strong>: The model was trained on the <strong>Shakespeare Dataset</strong>, offering a rich, text-heavy corpus that allowed for experimentation with natural language generation.</p> </li> <li> <strong>Training</strong>: <ul> <li>The model was trained overnight on a <strong>single RTX 4060 GPU (8GB)</strong>.</li> <li>Despite producing nonsensical sentences due to the model’s size, the project provided significant insights into the workings of neural networks for NLP tasks.</li> </ul> </li> </ul> <h2 id="core-concepts-explored">Core Concepts Explored</h2> <p>By implementing mini_GPT from scratch, I gained hands-on experience with the following key concepts fundamental to LLMs:</p> <ul> <li> <strong>Embeddings</strong>: Converting words or tokens into continuous vector representations.</li> <li> <strong>Tokens, Keys, and Queries</strong>: Understanding the attention mechanism and how tokens are processed in relation to each other.</li> <li> <strong>Multi-Head Attention</strong>: Distributing attention across multiple heads for improved representation learning.</li> <li> <strong>Residual Connections</strong>: Maintaining gradient flow through deep networks by allowing direct connections between layers.</li> </ul> <h2 id="project-insights">Project Insights</h2> <p>Although the generated text often didn’t make sense, working with <strong>mini_GPT</strong> deepened my understanding of how LLMs function and how training parameters affect model performance. The experience with embeddings, attention mechanisms, and optimization techniques was invaluable for future work in the field of NLP.</p> <hr> <h2 id="project-source-code">Project Source Code</h2> <p>You can find the complete source code and implementation details in the <a href="https://github.com/ChinChinati/mini_GPT/" rel="external nofollow noopener" target="_blank">mini_GPT GitHub Repository</a>.</p> <hr> <h2 id="code-usage-guidelines">Code Usage Guidelines</h2> <h3 id="installation">Installation</h3> <p>Ensure you have the following required packages installed:</p> <ul> <li><code class="language-plaintext highlighter-rouge">torch==2.4.0+cu121</code></li> <li>Python version <strong>3.10</strong> </li> </ul> <p>Install dependencies via pip:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span><span class="nv">torch</span><span class="o">==</span>2.4.0+cu121
</code></pre></div></div> <h3 id="prepare-the-dataset">Prepare the Dataset</h3> <p>Download the <strong>Shakespeare Dataset</strong> and place it in the <code class="language-plaintext highlighter-rouge">data/</code> folder.</p> <h2 id="running-the-code">Running the Code</h2> <p>The project contains two main files, <strong><code class="language-plaintext highlighter-rouge">v2.py</code></strong> and <strong><code class="language-plaintext highlighter-rouge">gpt.py</code></strong>, which differ in model size. Choose the file that suits your computational resources:</p> <ul> <li>Adjust the model size in the respective file by editing the configuration parameters such as the number of layers, attention heads, or embedding dimensions.</li> </ul> <h3 id="steps-to-run">Steps to Run:</h3> <ol> <li>Clone the repository: <div class="language-bash highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>git clone https://github.com/ChinChinati/mini_GPT.git
<span class="nb">cd </span>mini_GPT
</code></pre></div> </div> </li> </ol> <h3 id="run-the-training-script">Run the Training Script</h3> <p>Use one of the following commands to train the model, depending on the model size you prefer:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python v2.py
<span class="c"># or</span>
python gpt.py
</code></pre></div></div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Shailesh </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>